{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1\n",
    "Utilizando a base Titanic disponível no kaggle (https://www.kaggle.com/c/titanic/data) elabore uma solução utilizando dois algoritmos de aprendizagem de máquina do seu conhecimento para classificar se o passageiro tem ou não chance de sobreviver. Os resultados dessa questão deverão ser descritos detalhadamente no relatório.\n",
    "* Lembre de fazer todo o pré-processamento, explicando suas decisões;\n",
    "* Avalie os resultados usando diferentes métricas.\n",
    "* Teste 3 variações de parâmetros dos métodos;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pré-processamento\n",
    "\n",
    "É dado início ao pré-processamento, importando as bibliotecas necessárias e instanciando os databases forneceidos através do pandas.\n",
    "\n",
    "É importante entender que:\n",
    "* __gs__ equivale à instância do database que contém as saídas (coluna *Survived*) corretas para os testes\n",
    "* __tr__ equivale à instância do database que contém os treinos\n",
    "* __ts__ equivale à instância do database que contém os testes\n",
    "\n",
    "Vale lembrar que o database __gs__ refere-se ao __teste__, e que o __teste__ não pertence ao treino. Portanto será interessante unir os dois databases futuramente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn import cluster, neighbors, svm, metrics, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gs = pd.read_csv(\"data/gender_submission.csv\",sep=\",\")\n",
    "tr = pd.read_csv(\"data/train.csv\",sep=\",\")\n",
    "ts = pd.read_csv(\"data/test.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliando a quantidade de itens em cada database\n",
    "\n",
    "Para entender a quantidade de itens com o qual se está trabalhando, é feita uma leitura através do comando __*len()*__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do database de treino: 891\n",
      "Tamanho do database de testes: 418\n",
      "Tamanho do database que contém as saídas corretas do teste: 418\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho do database de treino:\", len(tr))\n",
    "print(\"Tamanho do database de testes:\", len(ts))\n",
    "print(\"Tamanho do database que contém as saídas corretas do teste:\", len(gs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unindo todos os databases\n",
    "\n",
    "Para passarem pelo pré-processamento, é interessante que todos os dados estejam juntos. Desta forma o __gs__ será unido ao __ts__, que será, por sua vez, unido ao __tr__.\n",
    "\n",
    "❗️ __Utilizaremos o termo *dfTotal* para se referir ao DataFrame completo, que inclui o teste e o treino.__ ❗️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotal = pd.concat([tr,pd.concat([gs, ts.drop(columns=['PassengerId'])], axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisando quantos itens nulos há no database\n",
    "\n",
    "É importante conhecer quantos itens nulos existem no database para entender qual deve ser a medida adequada a se tomar mediante a quantidade de itens nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->Nulidade:\n",
      "PassengerId       0\n",
      "Survived          0\n",
      "Pclass            0\n",
      "Name              0\n",
      "Sex               0\n",
      "Age             263\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Ticket            0\n",
      "Fare              1\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"-->Nulidade:\")\n",
    "print(dfTotal.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ __Os itens nulos de cabine representam, no treino, mais de 77% do total de informações. Excluir todas essas informações pode representar uma alta perda ao treinamento do IA, ao passo que completar todo esse conteúdo com informações aleatórias ou fixas também podem trazer algum nível de imprecisão aos testes. Desta forma, optou-se por excluir essa coluna.__ ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excluindo a coluna de Cabine\n",
    "\n",
    "Como dito acima, a coluna *Cabin* apresenta muitos valores nulos. Desta forma passa a ser interessante excluir essa coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotal = dfTotal.drop(columns=['Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisando quantos itens nulos há no database\n",
    "\n",
    "Ainda analisando a quantidade de elementos nulos, será feita a análise novamente agora sem a coluna de cabine, que previamente apresentou várias informações faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->Nulidade:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            263\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"-->Nulidade:\")\n",
    "print(dfTotal.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗️ __Considerando que *Fare* (Tarifa) e *Embarked* apresentam uma quantidade ínfima de valores nulos, considerou-se interessante, na coluna Fare, considerar a mediana no lugar do valor nulo e, no Embarked, o uso da moda dos valores.__ ❗️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substituindo valores de Fare, Age e Embarked\n",
    "\n",
    "Será considerada a moda dos valores de __Embarked__ para substituir os valores nulos e a mediana de __Fare__ e __Age__ para substituir os valores faltantes.\n",
    "\n",
    "Note que, por mais que haja uma quantidade mais expressiva de valores nulos para *Age*, isso representa apenas 20%, da quantidade total. Sendo assim é entendeu-se como viável substituir os valores de idade pela mediana de todas as idades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            263\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfTotal[\"Fare\"].fillna(dfTotal[\"Fare\"].median(), inplace=True)\n",
    "print(dfTotal.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            263\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfTotal[\"Embarked\"].fillna(dfTotal[\"Embarked\"].mode()[0],inplace=True)\n",
    "print(dfTotal.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfTotal[\"Age\"].fillna(dfTotal[\"Age\"].median(),inplace=True)\n",
    "print(dfTotal.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
